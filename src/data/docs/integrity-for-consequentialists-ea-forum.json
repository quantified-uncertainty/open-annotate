{
  "id": "integrity-for-consequentialists-ea-forum",
  "slug": "integrity-for-consequentialists-ea-forum",
  "title": "Integrity for consequentialists — EA Forum",
  "author": "Unknown Author",
  "publishedDate": "2025-04-15",
  "intendedAgents": [
    "bias-detector",
    "clarity-coach",
    "research-scholar"
  ],
  "content": "(Cross-posted from [the sideways view](https://sideways-view.com/2016/11/14/integrity-for-consequentialists/).)\n\nFor most people I don't think it's important to have a really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid.\n\n#### I.\n\nI aspire to make decisions in a pretty simple way. I think about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.\n\nTo make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option.\n\nIf I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one.\n\n![payshisdebts](https://unstylizedcom.files.wordpress.com/2016/11/payshisdebts.jpg)\n\n_Optimal summary of this post._\n\nIf I'm considering sharing a secret you told me, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would share this secret_. In many cases, that would mean that you wouldn't have shared it with me---a cost which is usually larger than whatever benefit I might gain from sharing it now.\n\nIf I'm considering having a friend's back, or deciding whether to be mean, or thinking about what exactly counts as \"betrayal,\" I'm doing the same calculus. (In practice there are many cases where I am pathologically unable to be really mean. One motivation for being really precise about integrity is recovering the ability to engage in normal levels of being a jerk when it's actually a good idea.)\n\nThis is a weird kind of effect, since it goes backwards in time and it may contradict what I've actually seen. If I **_know_** that you decided to share the secret with me, what does it mean to imagine my decision causing you not to have shared it?\n\nIt just means that I imagine the counterfactual where you didn't share the secret, and I think about just how bad that would have been---making the decision as if I did not yet know whether you would share it or not.\n\nI find the ideal of integrity very viscerally compelling, significantly moreso than other abstract beliefs or principles that I often act on.\n\n#### II.\n\nThis can get pretty confusing, and at the end of the day this simple statement is just an approximation. I could run through a lot of confusing examples and maybe sometime I should, but this post isn't the place for that.\n\nI'm not going to use some complicated reasoning to explain why screwing you over is consistent with integrity, I am just going to be straightforward. I think \"being straightforward\" is basically what you get if you do the complicated reasoning right. You can believe that or not, but one consequence of integrity is that I'm not going to try to mislead you about it. Another consequence is that when I'm dealing with you, I'm going to interpret integrity like I want you to think that I interpret it.\n\nIntegrity doesn't mean merely keeping my word. To the extent I want to interact with you I will be the kind of person you will be predictably glad to have interacted with. To that end, I am happy to do nice things that have no direct good consequences for me. I am hesitant to be vengeful; but if I think you've wronged me because you thought it would have no bad consequences for you, I am willing to do malicious things that have no direct good consequences for me.\n\nOn the flip side, integrity does not mean that I always keep my word. If you ask me a question that I don't want to answer, and me saying \"I don't think I should answer that\" would itself reveal information that I don't want to reveal, then I will probably lie. If I say I will do something then I will try to do it, but it just gets tallied up like any other cost or benefit, it's not a hard-and-fast rule. None of these cases are going to feel like gotchas; they are easy to predict given my definition of integrity, and I think they are in line with common-sense intuitions about being basically good.\n\nSome examples where things get more complicated: if we were trying to think of the same number between 1 and 20, I wouldn't assume that we are going to win because by choosing 17 I cause you to know that I'm the kind of person who picks 17. And if you invade Latvia I'm not going to bomb Moscow, assuming that by being arbitrarily vindictive I guarantee your non-aggression. If you want to figure out what I'd do in these cases, think UDT + the arguments in the rest of this post + a reasonable account of logical uncertainty. Or just ask. Sometimes the answer in fact depends on open philosophical questions. But while I find that integrity comes up surprisingly often, really hard decision-theoretic cases come up about as rarely as you'd expect.\n\nA convenient thing about this form of integrity is that it basically means behaving in the way that I'd want to claim to behave in this blog post. If you ask me \"doesn't this imply that you would do X, which you only refrained from writing down because it would reflect poorly on you?\" then you've answered your own question.\n\n#### III.\n\nWhy would I do this? At face value it may look a bit weird. People's expectations about me aren't shaped by a magical retrocausal influence from my future decision. Instead they are shaped by a messy basket of factors:\n\n*   Their past experiences with me.\n*   Their past experiences with other similar people.\n*   My reputation.\n*   Abstract reasoning about what I might do.\n*   Attempts to \"read\" my character and intentions from body language, things I say, and other intuitive cues.\n*   (And so on.)\n\nIn some sense, the total \"influence\" of these factors must add up to 100%.\n\nI think that basically all of these factors give reasons to behave with integrity:\n\n*   My decision is going to have a causal influence on what you think of me.\n*   My decision is going to have a causal influence on what you think of other similar people. I want to be nice to those people. But also my decision is correlated with their decisions (moreso the more they are like me) and I want _them_ to be nice to _me_.\n*   My decision is going to have a direct effect on my reputation.\n*   My decision has logical consequences on your reasoning about my decision. After all, I am running a certain kind of algorithm and you have some ability to imperfectly simulate that algorithm.\n*   To the extent that your attempts to infer my character or intention are unbiased, being the kind of person who will decide in a particular way will actually cause you to believe I am that kind of person.\n*   (And so on.)\n\nThe strength of each of those considerations depends on how significant each factor was in determining their views about me, and that will vary wildly from person to person and case to case. But if the total influence of all of these factors is really 100%, then just replacing them all with a magical retrocausal influence is going to result in basically the same decision.\n\nSome of these considerations are only relevant because I make decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here.\n\n#### IV.\n\nWhat about a really extreme case, where definitely no one will ever learn what I did, and where they don't know anything about me, and where they've never interacted with me or anyone similar to me before? In that case, should I go back to being a consequentialist jerk?\n\nThere is a temptation to reject this kind of crazy thought experiment---there are never literally _zero_ causal effects. But like most thought experiments, it is intended to explore an extreme point in the space of possibilities:![twopoints](https://unstylizedcom.files.wordpress.com/2016/11/twopoints.png)\n\nOf course we don't usually encounter these extreme cases; most of our decisions sit somewhere in between. The extreme cases are mostly interesting to the extent that realistic situations are in between them and we can usefully interpolate.\n\nFor example, you might think that the picture looks something like this:![line](https://unstylizedcom.files.wordpress.com/2016/11/line.png)\n\nOn this perspective, if I would be a jerk when _definitely for sure no one will know_ then presumably I am at least a little bit of a jerk when _it sure seems like no one will know_.\n\nBut actually I don't think the graph looks like this.\n\nSuppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points.\n\nIn reality, I think the graph is closer to this:![curve](https://unstylizedcom.files.wordpress.com/2016/11/curve.png)\n\nOur original thought experiment is an extremely special case, and the behavior changes rapidly as soon as we move a little bit away from it.\n\nAt any rate, these considerations significantly limit the applicability of intuitions from pathological scenarios, and tend to push optimal behavior closer to behaving with integrity.\n\nThis effect is especially pronounced when there are many possible channels through which my behavior can effect others' judgments, since then a crazy extreme case must be extreme with respect to every one of these indicators: my behavior must be unobservable, the relevant people must have no ability to infer my behavior from tells in advance, they must know nothing about the algorithm I am running, and so on.\n\n#### V.\n\nIntegrity has one more large advantage: it is often very efficient. Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful. (On the revenge side things are a bit more complicated, and I'm only really keen to be vengeful when the behavior was socially inefficient in addition to being bad for my values.)\n\nI'm generally keen to find efficient ways to do good for those around me. For one, I care about the people around me. For two, I feel pretty optimistic that if I create value, some of it will flow back to me. For three, I want to be the kind of person who is good to be around.\n\nSo if the optimal level of integrity from a social perspective is 100%, but from my personal perspective would be something close to 100%, I am more than happy to just go with 100%. I think this is probably one of the most cost-effective ways I can sacrifice a (tiny) bit of value in order to help those around me.\n\nOn top of that:\n\n*   Integrity is most effective when it is straightforward rather than conditional.\n*   \"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes.\n\nAfter putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity.\n\n#### VI.\n\nMany consequentialists claim to adopt firm rules like \"my word is inviolable\" and then justify those rules on consequentialist grounds. But I think on the one hand that approach is too demanding---the people I know who take promises most seriously basically never make them---and on the other it does not go far enough---someone bound by the literal content of their word is only a marginally more useful ally than someone with no scruples at all.\n\nPersonally, I get a lot of benefit from having clear definitions; I feel like the operationalization of integrity in this post has worked pretty well, and much better than the deontological constraints it replaced.  That said, I'm always interested in adopting something better, and would love to hear pushback or arguments for alternative norms.",
  "reviews": [
    {
      "agentId": "bias-detector",
      "costInCents": 7148,
      "createdAt": "2025-04-15T22:18:42.487Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":4880,\"completionTokens\":2268,\"totalTokens\":7148,\"temperature\":0.7,\"runtimeMs\":49214}",
      "summary": "This document presents a nuanced approach to consequentialist ethics with integrity as a central component. The author describes integrity not as rigid rule-following but as making decisions while considering how others would view them if they knew the author's decision-making process. While the framework appears thoughtful, it contains several biases. There's a strong individualistic Western bias that prioritizes personal utility calculations over communal values or universal principles. The document shows confirmation bias by selectively focusing on examples that support the author's framework while dismissing potential counterexamples as \"pathological scenarios.\" There's also a rationalization bias in justifying potentially deceptive behavior through complex reasoning. The text reveals status quo bias by assuming current social norms and power dynamics are optimal. Additionally, the author demonstrates overconfidence bias in asserting their approach is \"straightforward\" despite acknowledging its complexity. To improve, the document would benefit from considering diverse cultural perspectives, acknowledging power imbalances, exploring edge cases more thoroughly, and recognizing potential limitations of the framework.",
      "comments": [
        {
          "title": "Western Individualistic Bias",
          "description": "The document presents a highly individualistic approach to ethics that centers personal decision-making and utility calculations. This reflects Western philosophical traditions while potentially overlooking more communal or duty-based ethical frameworks common in many non-Western cultures. This bias may limit the framework's applicability across diverse cultural contexts where collective welfare, harmony, or adherence to traditional values might take precedence over individual utility calculations.",
          "highlight": {
            "startOffset": 408,
            "endOffset": 534,
            "quotedText": "consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.",
            "prefix": "I aspire to make decisions in a pretty simple way. I think about the "
          }
        },
        {
          "title": "Rationalization Bias",
          "description": "The author exhibits rationalization bias by developing complex reasoning to justify potentially deceptive or self-serving behaviors while maintaining a claim to integrity. This creates a framework where almost any action can be justified through sufficiently complex reasoning about hypothetical knowledge states of others. The bias manifests in creating exceptions to honesty that serve the author's interests while maintaining a self-perception of integrity.",
          "highlight": {
            "startOffset": 3775,
            "endOffset": 3962,
            "quotedText": "If you ask me a question that I don't want to answer, and me saying \"I don't think I should answer that\" would itself reveal information that I don't want to reveal, then I will probably lie.",
            "prefix": "On the flip side, integrity does not mean that I always keep my word. "
          }
        },
        {
          "title": "Status Quo Bias",
          "description": "The document demonstrates status quo bias by assuming current social norms and power dynamics are optimal or natural. The framework doesn't account for how integrity might function differently in contexts of systemic inequality or injustice. This bias appears when the author assumes that integrity naturally aligns with being \"basically good\" without examining whose definition of goodness is being centered or how power dynamics might influence these definitions.",
          "highlight": {
            "startOffset": 4181,
            "endOffset": 4310,
            "quotedText": "predict given my definition of integrity, and I think they are in line with common-sense intuitions about being basically good.",
            "prefix": " None of these cases are going to feel like gotchas; they are easy to "
          }
        },
        {
          "title": "Overconfidence Bias",
          "description": "The author demonstrates overconfidence bias by repeatedly characterizing their complex ethical framework as \"simple,\" \"straightforward,\" or \"basic\" despite acknowledging numerous complications and edge cases. This bias manifests in the assertion that the author's approach to integrity is intuitive and easy to apply, while simultaneously requiring sophisticated decision theory and philosophical reasoning that most people would find challenging to implement consistently.",
          "highlight": {
            "startOffset": 12303,
            "endOffset": 12404,
            "quotedText": "y straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity.",
            "prefix": "After putting all of this together, I feel like the calculus is prett"
          }
        }
      ]
    },
    {
      "agentId": "clarity-coach",
      "costInCents": 8035,
      "createdAt": "2025-04-15T22:19:37.269Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":5510,\"completionTokens\":2525,\"totalTokens\":8035,\"temperature\":0.7,\"runtimeMs\":54746}",
      "summary": "This document explores a nuanced view of integrity for consequentialists. The author defines integrity as making decisions while considering how others would act if they knew you were the kind of person who makes such decisions. This approach balances pure consequentialism with commitment-keeping, avoiding both short-sightedness and excessive timidity. The author argues that this form of integrity is both pragmatically beneficial and aligns with intuitive moral reasoning. They present a model where even in scenarios with low chances of detection, maintaining integrity remains optimal due to the disproportionate impact of discovered violations. The document acknowledges complexities in edge cases but maintains that straightforward integrity is computationally simpler and socially efficient. Unlike rigid deontological approaches to promises, this framework provides flexibility while preserving trustworthiness. The writing effectively uses personal reflection, hypothetical scenarios, and visual aids to convey a sophisticated ethical framework.",
      "comments": [
        {
          "title": "Clear Thesis Statement and Structure",
          "description": "The document effectively establishes its purpose in the introduction and maintains a clear organizational structure throughout. The numbered sections (I-VI) provide logical progression of ideas, making the complex philosophical argument accessible. This structural clarity significantly enhances readability, allowing readers to follow the development of the integrity concept from definition through justification to practical application.",
          "highlight": {
            "startOffset": 93,
            "endOffset": 331,
            "quotedText": "really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid.",
            "prefix": "For most people I don't think it's important to have a "
          }
        },
        {
          "title": "Balanced Sentence Structure Variation",
          "description": "The document effectively alternates between short, direct sentences and longer, more complex ones. This variation creates a natural reading rhythm that maintains engagement while allowing for the development of complex ideas. The balance prevents the philosophical content from becoming monotonous or overly dense, contributing significantly to the overall readability of the piece.",
          "highlight": {
            "startOffset": 397,
            "endOffset": 724,
            "quotedText": "about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.\n\nTo make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option.",
            "prefix": "I aspire to make decisions in a pretty simple way. I think "
          }
        },
        {
          "title": "Excessive Paragraph Length in Section III",
          "description": "The bullet-point list in Section III contains complex ideas that would benefit from further subdivision. Breaking this section into smaller, more focused paragraphs would improve readability by providing visual breaks and allowing readers to process each point more effectively. Consider expanding each bullet point into a short paragraph with a clear topic sentence and supporting explanation to enhance clarity and comprehension.",
          "highlight": {
            "startOffset": 5939,
            "endOffset": 6855,
            "quotedText": "add up to 100%.\n\nI think that basically all of these factors give reasons to behave with integrity:\n\n*   My decision is going to have a causal influence on what you think of me.\n*   My decision is going to have a causal influence on what you think of other similar people. I want to be nice to those people. But also my decision is correlated with their decisions (moreso the more they are like me) and I want _them_ to be nice to _me_.\n*   My decision is going to have a direct effect on my reputation.\n*   My decision has logical consequences on your reasoning about my decision. After all, I am running a certain kind of algorithm and you have some ability to imperfectly simulate that algorithm.\n*   To the extent that your attempts to infer my character or intention are unbiased, being the kind of person who will decide in a particular way will actually cause you to believe I am that kind of person.\n*   (And so on.)",
            "prefix": "In some sense, the total \"influence\" of these factors must "
          }
        },
        {
          "title": "Undefined Technical Term",
          "description": "The document uses the technical term \"UDT\" without defining it or providing context for readers unfamiliar with decision theory terminology. This creates a potential comprehension barrier for general audiences. Consider briefly explaining that UDT refers to \"Updateless Decision Theory\" and providing a one-sentence description of its relevance to the integrity framework being discussed.",
          "highlight": {
            "startOffset": 7294,
            "endOffset": 7568,
            "quotedText": "decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here.",
            "prefix": "Some of these considerations are only relevant because I make "
          }
        },
        {
          "title": "Strong Conclusion with Practical Application",
          "description": "The document concludes effectively by contrasting the author's approach with alternative consequentialist frameworks and inviting feedback. This conclusion successfully ties the theoretical discussion to practical ethical decision-making, emphasizing the real-world utility of the integrity framework. The openness to alternative perspectives demonstrates intellectual humility and invites continued dialogue on the topic.",
          "highlight": {
            "startOffset": 12759,
            "endOffset": 13207,
            "quotedText": "literal content of their word is only a marginally more useful ally than someone with no scruples at all.\n\nPersonally, I get a lot of benefit from having clear definitions; I feel like the operationalization of integrity in this post has worked pretty well, and much better than the deontological constraints it replaced.  That said, I'm always interested in adopting something better, and would love to hear pushback or arguments for alternative norms.",
            "prefix": "the other it does not go far enough---someone bound by the "
          }
        }
      ]
    },
    {
      "agentId": "research-scholar",
      "costInCents": 8550,
      "createdAt": "2025-04-15T22:21:48.900Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":5681,\"completionTokens\":2869,\"totalTokens\":8550,\"temperature\":0.7,\"runtimeMs\":50467}",
      "summary": "This essay explores a nuanced definition of integrity for consequentialists that balances pure outcome-maximization with trustworthiness. The author proposes a decision framework where one acts as if their choice reveals their character to others, even retroactively. This approach addresses the shortcomings of both naive consequentialism (which can be short-sighted) and rigid deontology (which can be unnecessarily constraining). The framework accounts for reputation effects, logical correlations between similar agents, and inference patterns others use to predict behavior. The author argues that even in scenarios with minimal social visibility, integrity remains valuable due to non-linear reputation effects - rare observations of bad behavior can trigger disproportionately large negative updates. The essay concludes that integrity is not only ethically sound but practically efficient, enabling commitment-making and positive-sum interactions without requiring explicit promises or rigid rules. This approach represents a more sophisticated consequentialism that incorporates the social dimension of decision-making.",
      "comments": [
        {
          "title": "Decision-Theoretic Foundations",
          "description": "The author's approach to integrity explicitly relies on Updateless Decision Theory (UDT) rather than Causal Decision Theory (CDT). This is significant in the rationalist community where decision theory discussions often center on how agents should reason about logical correlations between decisions and outcomes. UDT, developed by Wei Dai, allows agents to consider the logical implications of their decision algorithms rather than just causal effects. This framework is particularly relevant to the LessWrong community's interests in decision theory paradoxes and coordination problems.",
          "highlight": {
            "startOffset": 7294,
            "endOffset": 7568,
            "quotedText": "decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here.",
            "prefix": " a magical retrocausal influence is going to result in basically the same decision.\n\nSome of these considerations are only relevant because I make "
          }
        },
        {
          "title": "Bayesian Social Reasoning",
          "description": "The author describes a subtle Bayesian reasoning process where rare observations have disproportionate impact on belief updates. This is a sophisticated application of Bayesian epistemology to social interactions. In the rationalist community, this connects to discussions about proper scoring rules, information theory, and optimal inference. The insight that rarer observations should trigger larger updates is mathematically sound and represents the kind of probabilistic thinking that LessWrong promotes.",
          "highlight": {
            "startOffset": 9527,
            "endOffset": 9648,
            "quotedText": "once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.",
            "prefix": "her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so ("
          }
        },
        {
          "title": "Moloch and Coordination Solutions",
          "description": "The author's approach to integrity provides a potential solution to certain Molochian coordination problems, a concept frequently discussed on LessWrong (derived from Scott Alexander's Meditations on Moloch). By adopting a decision procedure that enables credible commitment-making without external enforcement, the author is describing a mechanism that could help overcome multipolar traps and prisoner's dilemmas. This relates to EA discussions about institutional design and mechanisms for cooperation in high-stakes global challenges.",
          "highlight": {
            "startOffset": 10779,
            "endOffset": 10985,
            "quotedText": "Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful.",
            "prefix": "Integrity has one more large advantage: it is often very efficient. "
          }
        },
        {
          "title": "Computational Simplicity as a Feature",
          "description": "The author notes that simple decision procedures have computational advantages over complex case-by-case calculations. This connects to discussions in rationalist circles about bounded rationality, computational constraints on decision-making, and the value of heuristics. It also relates to discussions about AI alignment, where simple, robust decision procedures may be preferable to complex utility calculations that could be vulnerable to edge cases or optimization failures.",
          "highlight": {
            "startOffset": 11864,
            "endOffset": 12026,
            "quotedText": "\"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.",
            "prefix": "On top of that:\n\n*   Integrity is most effective when it is straightforward rather than conditional.\n*   \""
          }
        },
        {
          "title": "Functional Definition vs. Deontological Rules",
          "description": "The author contrasts their functional definition of integrity with more rigid deontological approaches common among some consequentialists. This relates to ongoing discussions in the rationalist community about the role of rules, heuristics, and principles in ethical reasoning. The critique that deontological constraints can be simultaneously too demanding and insufficient connects to discussions about moral trade-offs, moral uncertainty, and rule-consequentialism that appear frequently on LessWrong and EA forums.",
          "highlight": {
            "startOffset": 12413,
            "endOffset": 12866,
            "quotedText": "Many consequentialists claim to adopt firm rules like \"my word is inviolable\" and then justify those rules on consequentialist grounds. But I think on the one hand that approach is too demanding---the people I know who take promises most seriously basically never make them---and on the other it does not go far enough---someone bound by the literal content of their word is only a marginally more useful ally than someone with no scruples at all.",
            "prefix": "After putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity.\n\n#### VI.\n\n"
          }
        }
      ]
    }
  ]
}