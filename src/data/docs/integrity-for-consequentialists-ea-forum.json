{
  "id": "integrity-for-consequentialists-ea-forum",
  "slug": "integrity-for-consequentialists-ea-forum",
  "title": "Integrity for consequentialists — EA Forum",
  "author": "Unknown Author",
  "publishedDate": "2025-04-15",
  "intendedAgents": [
    "bias-detector",
    "clarity-coach",
    "research-scholar"
  ],
  "content": "(Cross-posted from [the sideways view](https://sideways-view.com/2016/11/14/integrity-for-consequentialists/).)\n\nFor most people I don't think it's important to have a really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid.\n\n#### I.\n\nI aspire to make decisions in a pretty simple way. I think about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.\n\nTo make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option.\n\nIf I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one.\n\n![payshisdebts](https://unstylizedcom.files.wordpress.com/2016/11/payshisdebts.jpg)\n\n_Optimal summary of this post._\n\nIf I'm considering sharing a secret you told me, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would share this secret_. In many cases, that would mean that you wouldn't have shared it with me---a cost which is usually larger than whatever benefit I might gain from sharing it now.\n\nIf I'm considering having a friend's back, or deciding whether to be mean, or thinking about what exactly counts as \"betrayal,\" I'm doing the same calculus. (In practice there are many cases where I am pathologically unable to be really mean. One motivation for being really precise about integrity is recovering the ability to engage in normal levels of being a jerk when it's actually a good idea.)\n\nThis is a weird kind of effect, since it goes backwards in time and it may contradict what I've actually seen. If I **_know_** that you decided to share the secret with me, what does it mean to imagine my decision causing you not to have shared it?\n\nIt just means that I imagine the counterfactual where you didn't share the secret, and I think about just how bad that would have been---making the decision as if I did not yet know whether you would share it or not.\n\nI find the ideal of integrity very viscerally compelling, significantly moreso than other abstract beliefs or principles that I often act on.\n\n#### II.\n\nThis can get pretty confusing, and at the end of the day this simple statement is just an approximation. I could run through a lot of confusing examples and maybe sometime I should, but this post isn't the place for that.\n\nI'm not going to use some complicated reasoning to explain why screwing you over is consistent with integrity, I am just going to be straightforward. I think \"being straightforward\" is basically what you get if you do the complicated reasoning right. You can believe that or not, but one consequence of integrity is that I'm not going to try to mislead you about it. Another consequence is that when I'm dealing with you, I'm going to interpret integrity like I want you to think that I interpret it.\n\nIntegrity doesn't mean merely keeping my word. To the extent I want to interact with you I will be the kind of person you will be predictably glad to have interacted with. To that end, I am happy to do nice things that have no direct good consequences for me. I am hesitant to be vengeful; but if I think you've wronged me because you thought it would have no bad consequences for you, I am willing to do malicious things that have no direct good consequences for me.\n\nOn the flip side, integrity does not mean that I always keep my word. If you ask me a question that I don't want to answer, and me saying \"I don't think I should answer that\" would itself reveal information that I don't want to reveal, then I will probably lie. If I say I will do something then I will try to do it, but it just gets tallied up like any other cost or benefit, it's not a hard-and-fast rule. None of these cases are going to feel like gotchas; they are easy to predict given my definition of integrity, and I think they are in line with common-sense intuitions about being basically good.\n\nSome examples where things get more complicated: if we were trying to think of the same number between 1 and 20, I wouldn't assume that we are going to win because by choosing 17 I cause you to know that I'm the kind of person who picks 17. And if you invade Latvia I'm not going to bomb Moscow, assuming that by being arbitrarily vindictive I guarantee your non-aggression. If you want to figure out what I'd do in these cases, think UDT + the arguments in the rest of this post + a reasonable account of logical uncertainty. Or just ask. Sometimes the answer in fact depends on open philosophical questions. But while I find that integrity comes up surprisingly often, really hard decision-theoretic cases come up about as rarely as you'd expect.\n\nA convenient thing about this form of integrity is that it basically means behaving in the way that I'd want to claim to behave in this blog post. If you ask me \"doesn't this imply that you would do X, which you only refrained from writing down because it would reflect poorly on you?\" then you've answered your own question.\n\n#### III.\n\nWhy would I do this? At face value it may look a bit weird. People's expectations about me aren't shaped by a magical retrocausal influence from my future decision. Instead they are shaped by a messy basket of factors:\n\n*   Their past experiences with me.\n*   Their past experiences with other similar people.\n*   My reputation.\n*   Abstract reasoning about what I might do.\n*   Attempts to \"read\" my character and intentions from body language, things I say, and other intuitive cues.\n*   (And so on.)\n\nIn some sense, the total \"influence\" of these factors must add up to 100%.\n\nI think that basically all of these factors give reasons to behave with integrity:\n\n*   My decision is going to have a causal influence on what you think of me.\n*   My decision is going to have a causal influence on what you think of other similar people. I want to be nice to those people. But also my decision is correlated with their decisions (moreso the more they are like me) and I want _them_ to be nice to _me_.\n*   My decision is going to have a direct effect on my reputation.\n*   My decision has logical consequences on your reasoning about my decision. After all, I am running a certain kind of algorithm and you have some ability to imperfectly simulate that algorithm.\n*   To the extent that your attempts to infer my character or intention are unbiased, being the kind of person who will decide in a particular way will actually cause you to believe I am that kind of person.\n*   (And so on.)\n\nThe strength of each of those considerations depends on how significant each factor was in determining their views about me, and that will vary wildly from person to person and case to case. But if the total influence of all of these factors is really 100%, then just replacing them all with a magical retrocausal influence is going to result in basically the same decision.\n\nSome of these considerations are only relevant because I make decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here.\n\n#### IV.\n\nWhat about a really extreme case, where definitely no one will ever learn what I did, and where they don't know anything about me, and where they've never interacted with me or anyone similar to me before? In that case, should I go back to being a consequentialist jerk?\n\nThere is a temptation to reject this kind of crazy thought experiment---there are never literally _zero_ causal effects. But like most thought experiments, it is intended to explore an extreme point in the space of possibilities:![twopoints](https://unstylizedcom.files.wordpress.com/2016/11/twopoints.png)\n\nOf course we don't usually encounter these extreme cases; most of our decisions sit somewhere in between. The extreme cases are mostly interesting to the extent that realistic situations are in between them and we can usefully interpolate.\n\nFor example, you might think that the picture looks something like this:![line](https://unstylizedcom.files.wordpress.com/2016/11/line.png)\n\nOn this perspective, if I would be a jerk when _definitely for sure no one will know_ then presumably I am at least a little bit of a jerk when _it sure seems like no one will know_.\n\nBut actually I don't think the graph looks like this.\n\nSuppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points.\n\nIn reality, I think the graph is closer to this:![curve](https://unstylizedcom.files.wordpress.com/2016/11/curve.png)\n\nOur original thought experiment is an extremely special case, and the behavior changes rapidly as soon as we move a little bit away from it.\n\nAt any rate, these considerations significantly limit the applicability of intuitions from pathological scenarios, and tend to push optimal behavior closer to behaving with integrity.\n\nThis effect is especially pronounced when there are many possible channels through which my behavior can effect others' judgments, since then a crazy extreme case must be extreme with respect to every one of these indicators: my behavior must be unobservable, the relevant people must have no ability to infer my behavior from tells in advance, they must know nothing about the algorithm I am running, and so on.\n\n#### V.\n\nIntegrity has one more large advantage: it is often very efficient. Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful. (On the revenge side things are a bit more complicated, and I'm only really keen to be vengeful when the behavior was socially inefficient in addition to being bad for my values.)\n\nI'm generally keen to find efficient ways to do good for those around me. For one, I care about the people around me. For two, I feel pretty optimistic that if I create value, some of it will flow back to me. For three, I want to be the kind of person who is good to be around.\n\nSo if the optimal level of integrity from a social perspective is 100%, but from my personal perspective would be something close to 100%, I am more than happy to just go with 100%. I think this is probably one of the most cost-effective ways I can sacrifice a (tiny) bit of value in order to help those around me.\n\nOn top of that:\n\n*   Integrity is most effective when it is straightforward rather than conditional.\n*   \"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes.\n\nAfter putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity.\n\n#### VI.\n\nMany consequentialists claim to adopt firm rules like \"my word is inviolable\" and then justify those rules on consequentialist grounds. But I think on the one hand that approach is too demanding---the people I know who take promises most seriously basically never make them---and on the other it does not go far enough---someone bound by the literal content of their word is only a marginally more useful ally than someone with no scruples at all.\n\nPersonally, I get a lot of benefit from having clear definitions; I feel like the operationalization of integrity in this post has worked pretty well, and much better than the deontological constraints it replaced.  That said, I'm always interested in adopting something better, and would love to hear pushback or arguments for alternative norms.",
  "reviews": [
    {
      "agentId": "bias-detector",
      "costInCents": 7790,
      "createdAt": "2025-04-16T00:34:33.715Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":5588,\"completionTokens\":2202,\"totalTokens\":7790,\"temperature\":0.7,\"runtimeMs\":41653}",
      "summary": "This document presents a consequentialist approach to integrity that balances ethical considerations with outcome optimization. The author defines integrity as making decisions while imagining that everyone knows they are the type of person who would make such decisions. This framework provides a middle ground between rigid rule-following and unprincipled consequentialism. The text exhibits several biases, including individualistic bias (emphasizing personal decision-making without addressing systemic factors), privileged perspective bias (assuming others share similar social contexts and power dynamics), and rationalist community bias (using decision theory terminology without sufficient explanation for general audiences). The document also contains confirmation bias in selecting examples that support the author's framework while minimizing potential counterexamples. Overall, the essay presents a thoughtful but somewhat narrow perspective on integrity that would benefit from acknowledging diverse cultural perspectives, power imbalances, and the limitations of purely consequentialist thinking.",
      "comments": [
        {
          "title": "Individualistic Decision-Making Bias",
          "description": "The framework presented focuses exclusively on individual decision-making without addressing how integrity functions in collective contexts or how it relates to systemic issues. This individualistic approach may overlook important social dimensions of ethics and integrity that involve community standards, shared responsibilities, and collective action problems.",
          "highlight": {
            "startOffset": 113,
            "endOffset": 610,
            "quotedText": "For most people I don't think it's important to have a really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid.\n\n#### I.\n\nI aspire to make decisions in a pretty simple way. I think about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best."
          },
          "isValid": false,
          "error": "Highlight overlaps with a previous highlight"
        },
        {
          "title": "Western Philosophical Bias",
          "description": "The text approaches ethics primarily through a Western philosophical lens, specifically consequentialism, without acknowledging non-Western ethical frameworks or alternative cultural perspectives on integrity. This limits the universality of the proposed framework and may alienate readers from different cultural backgrounds who might conceptualize integrity through different philosophical traditions.",
          "highlight": {
            "startOffset": 415,
            "endOffset": 800,
            "quotedText": "I aspire to make decisions in a pretty simple way. I think about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.\n\nTo make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option."
          },
          "isValid": true
        },
        {
          "title": "Confirmation Bias in Examples",
          "description": "The author primarily selects examples and scenarios that work well with their framework while giving less attention to potential counterexamples or scenarios where their approach might fail. This selective presentation of evidence reinforces the author's position without adequately addressing potential weaknesses in the proposed integrity framework.",
          "highlight": {
            "startOffset": 802,
            "endOffset": 1188,
            "quotedText": "If I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one."
          },
          "isValid": true
        },
        {
          "title": "Privileged Perspective Bias",
          "description": "The text assumes a relatively equal power dynamic between all parties involved in interactions, overlooking how integrity might function differently for those with less social power or in marginalized positions. This perspective fails to account for how social inequalities might constrain ethical choices or how integrity might need to be conceptualized differently across different power positions.",
          "highlight": {
            "startOffset": 3866,
            "endOffset": 4273,
            "quotedText": "On the flip side, integrity does not mean that I always keep my word. If you ask me a question that I don't want to answer, and me saying \"I don't think I should answer that\" would itself reveal information that I don't want to reveal, then I will probably lie. If I say I will do something then I will try to do it, but it just gets tallied up like any other cost or benefit, it's not a hard-and-fast rule."
          },
          "isValid": true
        },
        {
          "title": "Rationalist Community Jargon Bias",
          "description": "The text employs specialized terminology and concepts from rationalist and decision theory communities (like \"UDT\" and other technical concepts) without sufficient explanation, creating an accessibility barrier for readers unfamiliar with these concepts. This in-group language bias limits the reach and applicability of the ideas presented to a broader audience.",
          "highlight": {
            "startOffset": 4472,
            "endOffset": 4998,
            "quotedText": "Some examples where things get more complicated: if we were trying to think of the same number between 1 and 20, I wouldn't assume that we are going to win because by choosing 17 I cause you to know that I'm the kind of person who picks 17. And if you invade Latvia I'm not going to bomb Moscow, assuming that by being arbitrarily vindictive I guarantee your non-aggression. If you want to figure out what I'd do in these cases, think UDT + the arguments in the rest of this post + a reasonable account of logical uncertainty."
          },
          "isValid": true
        },
        {
          "title": "False Dichotomy Bias",
          "description": "The text presents a somewhat false dichotomy between consequentialism with integrity and consequentialism without integrity (\"being a consequentialist jerk\"), overlooking other ethical frameworks that might offer different approaches to integrity. This framing artificially narrows the discussion and excludes alternative perspectives that don't fit into this binary.",
          "highlight": {
            "startOffset": 7778,
            "endOffset": 8170,
            "quotedText": "What about a really extreme case, where definitely no one will ever learn what I did, and where they don't know anything about me, and where they've never interacted with me or anyone similar to me before? In that case, should I go back to being a consequentialist jerk?\n\nThere is a temptation to reject this kind of crazy thought experiment---there are never literally _zero_ causal effects."
          },
          "isValid": true
        },
        {
          "title": "Mathematical Modeling Bias",
          "description": "The text relies heavily on mathematical and graphical representations of human behavior and ethical decision-making, potentially oversimplifying complex social and psychological phenomena. This approach assumes that human ethical reasoning can be adequately captured through simplified models, which may not account for the full complexity of moral intuitions and social dynamics.",
          "highlight": {
            "startOffset": 8358,
            "endOffset": 8738,
            "quotedText": "Of course we don't usually encounter these extreme cases; most of our decisions sit somewhere in between. The extreme cases are mostly interesting to the extent that realistic situations are in between them and we can usefully interpolate.\n\nFor example, you might think that the picture looks something like this:![line](https://unstylizedcom.files.wordpress.com/2016/11/line.png)"
          },
          "isValid": true
        },
        {
          "title": "Self-Interest Assumption Bias",
          "description": "The framework assumes that people primarily act out of self-interest and need rational justifications for prosocial behavior. This view may underestimate the extent to which humans naturally value cooperation, fairness, and other prosocial behaviors for their own sake, not merely as instrumental means to personal benefit.",
          "highlight": {
            "startOffset": 11567,
            "endOffset": 12027,
            "quotedText": "I'm generally keen to find efficient ways to do good for those around me. For one, I care about the people around me. For two, I feel pretty optimistic that if I create value, some of it will flow back to me. For three, I want to be the kind of person who is good to be around.\n\nSo if the optimal level of integrity from a social perspective is 100%, but from my personal perspective would be something close to 100%, I am more than happy to just go with 100%."
          },
          "isValid": true
        },
        {
          "title": "Technological Metaphor Bias",
          "description": "The text frequently employs computational and mathematical metaphors to describe human ethical reasoning, which may bias understanding toward a mechanistic view of ethics. This framing can overlook the embodied, contextual, and relational aspects of ethical decision-making that aren't easily captured in computational terms.",
          "highlight": {
            "startOffset": 12267,
            "endOffset": 12637,
            "quotedText": "\"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes."
          },
          "isValid": false,
          "error": "Highlight overlaps with a previous highlight"
        },
        {
          "title": "Emotional Reasoning Dismissal Bias",
          "description": "While the text briefly mentions emotional responses, it generally presents them as mechanisms to be leveraged rather than as valid sources of moral insight in their own right. This bias toward rational calculation over emotional understanding may undervalue important aspects of human ethical reasoning that aren't easily reducible to consequentialist calculations.",
          "highlight": {
            "startOffset": 12435,
            "endOffset": 12813,
            "quotedText": "Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes.\n\nAfter putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity."
          },
          "isValid": true
        }
      ]
    },
    {
      "agentId": "clarity-coach",
      "costInCents": 8521,
      "createdAt": "2025-04-16T00:35:40.055Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":6218,\"completionTokens\":2303,\"totalTokens\":8521,\"temperature\":0.7,\"runtimeMs\":49355}",
      "summary": "This document presents a nuanced view of integrity from a consequentialist perspective. The author defines integrity not as rigid rule-following, but as making decisions while considering how others would react if they knew you were the kind of person who makes such decisions. This approach balances short-term gains against long-term reputation effects. The author argues that even in scenarios where actions might seem undetectable, various factors (reputation effects, logical correlations with similar actors, and others' ability to predict behavior) still incentivize integrity. The piece effectively uses visual graphs to illustrate how the payoff curve for integrity remains high even when detection probability decreases. The writing is clear and well-structured, progressing logically through defining integrity, explaining its personal implementation, addressing potential objections, and examining edge cases. The author maintains a conversational tone while tackling complex decision theory concepts, making sophisticated ideas accessible without oversimplification.",
      "comments": [
        {
          "title": "Strong Introduction with Clear Purpose Statement",
          "description": "The introduction effectively establishes the purpose and scope of the discussion. It clearly states why a precise definition of integrity matters for consequentialists specifically, setting up the problem to be solved. The language is direct and accessible, immediately engaging the reader with the practical implications of the philosophical discussion to follow.",
          "highlight": {
            "startOffset": 113,
            "endOffset": 404,
            "quotedText": "For most people I don't think it's important to have a really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid."
          },
          "isValid": true
        },
        {
          "title": "Consistent Section Structure Enhances Navigation",
          "description": "The document uses clear, numbered section headings (I through VI) that create a logical progression through the argument. This consistent structure helps readers navigate the content and understand how each section contributes to the overall thesis. The organization follows a natural flow: definition, personal implementation, justification, edge cases, practical benefits, and comparison to alternatives. This structural clarity enhances readability despite the complexity of the subject matter.",
          "highlight": {
            "startOffset": 406,
            "endOffset": 12823,
            "quotedText": "#### I.\n\nI aspire to make decisions in a pretty simple way. I think about the consequences of each possible action and decide how much I like them; then I select the action whose consequences I like best.\n\nTo make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option.\n\nIf I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one.\n\n![payshisdebts](https://unstylizedcom.files.wordpress.com/2016/11/payshisdebts.jpg)\n\n_Optimal summary of this post._\n\nIf I'm considering sharing a secret you told me, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would share this secret_. In many cases, that would mean that you wouldn't have shared it with me---a cost which is usually larger than whatever benefit I might gain from sharing it now.\n\nIf I'm considering having a friend's back, or deciding whether to be mean, or thinking about what exactly counts as \"betrayal,\" I'm doing the same calculus. (In practice there are many cases where I am pathologically unable to be really mean. One motivation for being really precise about integrity is recovering the ability to engage in normal levels of being a jerk when it's actually a good idea.)\n\nThis is a weird kind of effect, since it goes backwards in time and it may contradict what I've actually seen. If I **_know_** that you decided to share the secret with me, what does it mean to imagine my decision causing you not to have shared it?\n\nIt just means that I imagine the counterfactual where you didn't share the secret, and I think about just how bad that would have been---making the decision as if I did not yet know whether you would share it or not.\n\nI find the ideal of integrity very viscerally compelling, significantly moreso than other abstract beliefs or principles that I often act on.\n\n#### II.\n\nThis can get pretty confusing, and at the end of the day this simple statement is just an approximation. I could run through a lot of confusing examples and maybe sometime I should, but this post isn't the place for that.\n\nI'm not going to use some complicated reasoning to explain why screwing you over is consistent with integrity, I am just going to be straightforward. I think \"being straightforward\" is basically what you get if you do the complicated reasoning right. You can believe that or not, but one consequence of integrity is that I'm not going to try to mislead you about it. Another consequence is that when I'm dealing with you, I'm going to interpret integrity like I want you to think that I interpret it.\n\nIntegrity doesn't mean merely keeping my word. To the extent I want to interact with you I will be the kind of person you will be predictably glad to have interacted with. To that end, I am happy to do nice things that have no direct good consequences for me. I am hesitant to be vengeful; but if I think you've wronged me because you thought it would have no bad consequences for you, I am willing to do malicious things that have no direct good consequences for me.\n\nOn the flip side, integrity does not mean that I always keep my word. If you ask me a question that I don't want to answer, and me saying \"I don't think I should answer that\" would itself reveal information that I don't want to reveal, then I will probably lie. If I say I will do something then I will try to do it, but it just gets tallied up like any other cost or benefit, it's not a hard-and-fast rule. None of these cases are going to feel like gotchas; they are easy to predict given my definition of integrity, and I think they are in line with common-sense intuitions about being basically good.\n\nSome examples where things get more complicated: if we were trying to think of the same number between 1 and 20, I wouldn't assume that we are going to win because by choosing 17 I cause you to know that I'm the kind of person who picks 17. And if you invade Latvia I'm not going to bomb Moscow, assuming that by being arbitrarily vindictive I guarantee your non-aggression. If you want to figure out what I'd do in these cases, think UDT + the arguments in the rest of this post + a reasonable account of logical uncertainty. Or just ask. Sometimes the answer in fact depends on open philosophical questions. But while I find that integrity comes up surprisingly often, really hard decision-theoretic cases come up about as rarely as you'd expect.\n\nA convenient thing about this form of integrity is that it basically means behaving in the way that I'd want to claim to behave in this blog post. If you ask me \"doesn't this imply that you would do X, which you only refrained from writing down because it would reflect poorly on you?\" then you've answered your own question.\n\n#### III.\n\nWhy would I do this? At face value it may look a bit weird. People's expectations about me aren't shaped by a magical retrocausal influence from my future decision. Instead they are shaped by a messy basket of factors:\n\n*   Their past experiences with me.\n*   Their past experiences with other similar people.\n*   My reputation.\n*   Abstract reasoning about what I might do.\n*   Attempts to \"read\" my character and intentions from body language, things I say, and other intuitive cues.\n*   (And so on.)\n\nIn some sense, the total \"influence\" of these factors must add up to 100%.\n\nI think that basically all of these factors give reasons to behave with integrity:\n\n*   My decision is going to have a causal influence on what you think of me.\n*   My decision is going to have a causal influence on what you think of other similar people. I want to be nice to those people. But also my decision is correlated with their decisions (moreso the more they are like me) and I want _them_ to be nice to _me_.\n*   My decision is going to have a direct effect on my reputation.\n*   My decision has logical consequences on your reasoning about my decision. After all, I am running a certain kind of algorithm and you have some ability to imperfectly simulate that algorithm.\n*   To the extent that your attempts to infer my character or intention are unbiased, being the kind of person who will decide in a particular way will actually cause you to believe I am that kind of person.\n*   (And so on.)\n\nThe strength of each of those considerations depends on how significant each factor was in determining their views about me, and that will vary wildly from person to person and case to case. But if the total influence of all of these factors is really 100%, then just replacing them all with a magical retrocausal influence is going to result in basically the same decision.\n\nSome of these considerations are only relevant because I make decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here.\n\n#### IV.\n\nWhat about a really extreme case, where definitely no one will ever learn what I did, and where they don't know anything about me, and where they've never interacted with me or anyone similar to me before? In that case, should I go back to being a consequentialist jerk?\n\nThere is a temptation to reject this kind of crazy thought experiment---there are never literally _zero_ causal effects. But like most thought experiments, it is intended to explore an extreme point in the space of possibilities:![twopoints](https://unstylizedcom.files.wordpress.com/2016/11/twopoints.png)\n\nOf course we don't usually encounter these extreme cases; most of our decisions sit somewhere in between. The extreme cases are mostly interesting to the extent that realistic situations are in between them and we can usefully interpolate.\n\nFor example, you might think that the picture looks something like this:![line](https://unstylizedcom.files.wordpress.com/2016/11/line.png)\n\nOn this perspective, if I would be a jerk when _definitely for sure no one will know_ then presumably I am at least a little bit of a jerk when _it sure seems like no one will know_.\n\nBut actually I don't think the graph looks like this.\n\nSuppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points.\n\nIn reality, I think the graph is closer to this:![curve](https://unstylizedcom.files.wordpress.com/2016/11/curve.png)\n\nOur original thought experiment is an extremely special case, and the behavior changes rapidly as soon as we move a little bit away from it.\n\nAt any rate, these considerations significantly limit the applicability of intuitions from pathological scenarios, and tend to push optimal behavior closer to behaving with integrity.\n\nThis effect is especially pronounced when there are many possible channels through which my behavior can effect others' judgments, since then a crazy extreme case must be extreme with respect to every one of these indicators: my behavior must be unobservable, the relevant people must have no ability to infer my behavior from tells in advance, they must know nothing about the algorithm I am running, and so on.\n\n#### V.\n\nIntegrity has one more large advantage: it is often very efficient. Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful. (On the revenge side things are a bit more complicated, and I'm only really keen to be vengeful when the behavior was socially inefficient in addition to being bad for my values.)\n\nI'm generally keen to find efficient ways to do good for those around me. For one, I care about the people around me. For two, I feel pretty optimistic that if I create value, some of it will flow back to me. For three, I want to be the kind of person who is good to be around.\n\nSo if the optimal level of integrity from a social perspective is 100%, but from my personal perspective would be something close to 100%, I am more than happy to just go with 100%. I think this is probably one of the most cost-effective ways I can sacrifice a (tiny) bit of value in order to help those around me.\n\nOn top of that:\n\n*   Integrity is most effective when it is straightforward rather than conditional.\n*   \"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes.\n\nAfter putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity.\n\n#### VI."
          },
          "isValid": true
        },
        {
          "title": "Effective Use of Concrete Examples",
          "description": "The author strengthens abstract concepts with concrete, relatable examples. This section demonstrates how integrity works in practical scenarios like promise-keeping and secret-sharing, making the philosophical concept tangible. Each example clearly illustrates the backward-looking decision process that defines the author's approach to integrity, enhancing reader comprehension of an otherwise abstract concept.",
          "highlight": {
            "startOffset": 802,
            "endOffset": 1647,
            "quotedText": "If I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one.\n\n![payshisdebts](https://unstylizedcom.files.wordpress.com/2016/11/payshisdebts.jpg)\n\n_Optimal summary of this post._\n\nIf I'm considering sharing a secret you told me, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would share this secret_. In many cases, that would mean that you wouldn't have shared it with me---a cost which is usually larger than whatever benefit I might gain from sharing it now."
          },
          "isValid": true
        },
        {
          "title": "Clarifying Complex Counterfactual Reasoning",
          "description": "This passage effectively addresses a potential point of confusion about the author's decision framework. By directly confronting the apparent paradox in their reasoning (how past events can be affected by current decisions), the author demonstrates intellectual honesty while providing necessary clarification. The explanation of counterfactual thinking makes a complex concept more accessible without oversimplification.",
          "highlight": {
            "startOffset": 2051,
            "endOffset": 2517,
            "quotedText": "This is a weird kind of effect, since it goes backwards in time and it may contradict what I've actually seen. If I **_know_** that you decided to share the secret with me, what does it mean to imagine my decision causing you not to have shared it?\n\nIt just means that I imagine the counterfactual where you didn't share the secret, and I think about just how bad that would have been---making the decision as if I did not yet know whether you would share it or not."
          },
          "isValid": true
        },
        {
          "title": "Straightforward Acknowledgment of Limitations",
          "description": "The author enhances credibility by acknowledging the limitations of their framework rather than overreaching. This passage shows intellectual honesty by addressing potential edge cases and admitting that the simple definition provided is an approximation. This transparency builds trust with readers and prevents misunderstandings about the scope and application of the integrity framework being presented.",
          "highlight": {
            "startOffset": 2672,
            "endOffset": 3044,
            "quotedText": "This can get pretty confusing, and at the end of the day this simple statement is just an approximation. I could run through a lot of confusing examples and maybe sometime I should, but this post isn't the place for that.\n\nI'm not going to use some complicated reasoning to explain why screwing you over is consistent with integrity, I am just going to be straightforward."
          },
          "isValid": true
        },
        {
          "title": "Effective Visual Aids for Complex Concepts",
          "description": "The author skillfully uses visual graphs to illustrate the relationship between detection probability and optimal behavior. These visual elements transform an abstract discussion about edge cases into a clear conceptual model that readers can easily grasp. The progression of graphs (from points to line to curve) effectively builds the author's argument that integrity remains valuable even when detection probability is low, making a sophisticated point more accessible.",
          "highlight": {
            "startOffset": 8050,
            "endOffset": 10500,
            "quotedText": "There is a temptation to reject this kind of crazy thought experiment---there are never literally _zero_ causal effects. But like most thought experiments, it is intended to explore an extreme point in the space of possibilities:![twopoints](https://unstylizedcom.files.wordpress.com/2016/11/twopoints.png)\n\nOf course we don't usually encounter these extreme cases; most of our decisions sit somewhere in between. The extreme cases are mostly interesting to the extent that realistic situations are in between them and we can usefully interpolate.\n\nFor example, you might think that the picture looks something like this:![line](https://unstylizedcom.files.wordpress.com/2016/11/line.png)\n\nOn this perspective, if I would be a jerk when _definitely for sure no one will know_ then presumably I am at least a little bit of a jerk when _it sure seems like no one will know_.\n\nBut actually I don't think the graph looks like this.\n\nSuppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points.\n\nIn reality, I think the graph is closer to this:![curve](https://unstylizedcom.files.wordpress.com/2016/11/curve.png)\n\nOur original thought experiment is an extremely special case, and the behavior changes rapidly as soon as we move a little bit away from it."
          },
          "isValid": true
        },
        {
          "title": "Clear Explanation of Detection Probability Effects",
          "description": "This passage effectively explains why the relationship between detection probability and optimal behavior is non-linear. The author uses a concrete example with clear numerical values (50% vs. 5% detection chance) to illustrate three distinct mechanisms that cause low-probability detection to have disproportionate effects. This explanation strengthens the author's theoretical model by providing logical reasoning for why the curve takes its particular shape.",
          "highlight": {
            "startOffset": 8979,
            "endOffset": 10239,
            "quotedText": "Suppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points."
          },
          "isValid": false,
          "error": "Highlight overlaps with a previous highlight"
        },
        {
          "title": "Practical Benefits Section Enhances Persuasiveness",
          "description": "This section strengthens the argument by moving beyond theoretical justifications to practical advantages. By highlighting the efficiency benefits of integrity, the author appeals to readers who might be unconvinced by purely philosophical reasoning. The three clear points about creating value demonstrate that integrity isn't just morally sound but practically advantageous, making the argument more compelling for pragmatically-minded readers.",
          "highlight": {
            "startOffset": 11110,
            "endOffset": 11844,
            "quotedText": "Integrity has one more large advantage: it is often very efficient. Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful. (On the revenge side things are a bit more complicated, and I'm only really keen to be vengeful when the behavior was socially inefficient in addition to being bad for my values.)\n\nI'm generally keen to find efficient ways to do good for those around me. For one, I care about the people around me. For two, I feel pretty optimistic that if I create value, some of it will flow back to me. For three, I want to be the kind of person who is good to be around."
          },
          "isValid": true
        },
        {
          "title": "Effective Simplification of Decision Process",
          "description": "The author skillfully addresses the practical implementation challenge by acknowledging the computational and psychological advantages of a simpler approach. This passage adds credibility by showing awareness of human cognitive limitations and emotional factors. By explaining why they don't constantly recalculate optimal integrity levels, the author makes their framework more practical and actionable for readers who might otherwise find the approach too theoretical.",
          "highlight": {
            "startOffset": 12162,
            "endOffset": 12813,
            "quotedText": "On top of that:\n\n*   Integrity is most effective when it is straightforward rather than conditional.\n*   \"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes.\n\nAfter putting all of this together, I feel like the calculus is pretty straightforward. So I usually don't think about it, and just (aspire to) make decisions with integrity."
          },
          "isValid": true
        },
        {
          "title": "Balanced Critique of Alternative Approaches",
          "description": "The conclusion effectively distinguishes the author's approach from other consequentialist frameworks. By identifying specific limitations of rigid rule-based approaches (\"too demanding\" yet \"not far enough\"), the author clarifies the advantages of their more flexible integrity model. This comparison helps readers understand what makes this approach distinctive and potentially superior to alternatives, while the invitation for feedback demonstrates intellectual openness.",
          "highlight": {
            "startOffset": 12825,
            "endOffset": 13620,
            "quotedText": "Many consequentialists claim to adopt firm rules like \"my word is inviolable\" and then justify those rules on consequentialist grounds. But I think on the one hand that approach is too demanding---the people I know who take promises most seriously basically never make them---and on the other it does not go far enough---someone bound by the literal content of their word is only a marginally more useful ally than someone with no scruples at all.\n\nPersonally, I get a lot of benefit from having clear definitions; I feel like the operationalization of integrity in this post has worked pretty well, and much better than the deontological constraints it replaced.  That said, I'm always interested in adopting something better, and would love to hear pushback or arguments for alternative norms."
          },
          "isValid": true
        }
      ]
    },
    {
      "agentId": "research-scholar",
      "costInCents": 9258,
      "createdAt": "2025-04-16T00:36:52.454Z",
      "runDetails": "{\"model\":\"anthropic/claude-3.7-sonnet\",\"promptTokens\":6389,\"completionTokens\":2869,\"totalTokens\":9258,\"temperature\":0.7,\"runtimeMs\":55979}",
      "summary": "This essay explores a consequentialist framework for integrity that balances effectiveness with ethical behavior. The author defines integrity as making decisions while imagining that everyone knows what kind of person you are based on those decisions. This approach considers the counterfactual costs of actions—like breaking promises or sharing secrets—by calculating how others would have behaved differently had they known you would act this way. The framework doesn't require absolute adherence to promises but maintains straightforwardness in dealings. Several factors justify this approach: direct effects on reputation, impacts on similar people, logical consequences in others' reasoning about you, and others' ability to detect your character. The author argues that even in scenarios with low chances of detection, the magnitude of negative judgment increases proportionally, creating a non-linear relationship between secrecy and optimal behavior. This form of integrity enables commitments necessary for positive-sum interactions while being computationally simpler than calculating exact moral tradeoffs for each situation.",
      "comments": [
        {
          "title": "Consequentialism with Long-Term Vision",
          "description": "The author is attempting to reconcile consequentialism with integrity-based ethics, addressing a common critique that pure consequentialism can lead to short-sighted or overly timid decision-making. This connects to Derek Parfit's work on moral philosophy and Samuel Scheffler's agent-centered prerogatives. In the LessWrong/EA context, this relates to discussions about \"integrity\" as a constraint on pure utilitarian thinking (similar to Bernard Williams' critique of utilitarianism) while maintaining consequentialist foundations. The author is essentially proposing a sophisticated form of rule consequentialism that accounts for decision-theoretic considerations.",
          "highlight": {
            "startOffset": 113,
            "endOffset": 404,
            "quotedText": "For most people I don't think it's important to have a really precise definition of integrity. But if you really want to go all-in on consequentialism then I think it's useful. Otherwise you risk being stuck with a flavor of consequentialism that is either short-sighted or terminally timid."
          },
          "isValid": true
        },
        {
          "title": "Integrity as Character-Based Consequentialism",
          "description": "The author's approach represents a character-based form of consequentialism that has similarities with virtue ethics while maintaining consequentialist foundations. This connects to philosophical work on virtue consequentialism (e.g., Julia Driver) and character-based approaches to ethics. In the rationalist context, this relates to discussions about \"being the sort of agent who...\" framing of ethical decisions. The approach treats one's character or decision algorithm as the object of optimization rather than individual actions, which connects to discussions about \"policy-level\" versus \"act-level\" decision-making in the rationalist community. This perspective helps bridge consequentialist and virtue-based ethical frameworks.",
          "highlight": {
            "startOffset": 612,
            "endOffset": 1188,
            "quotedText": "To make decisions with integrity, I make one change: when I imagine picking an action, I pretend that picking it causes everyone to know that I am the kind of person who picks that option.\n\nIf I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one."
          },
          "isValid": false,
          "error": "Highlight overlaps with a previous highlight"
        },
        {
          "title": "Integrity in Asymmetric Information Contexts",
          "description": "The author discusses how integrity functions in contexts of asymmetric information, particularly around promise-breaking and secret-sharing. This connects to economic literature on principal-agent problems and information asymmetries (e.g., work by George Akerlof). In the rationalist community, this relates to discussions about coordination problems and commitment mechanisms. The author's approach provides a framework for maintaining cooperation in situations where verification is difficult, which has implications for institutional design and social trust mechanisms. This perspective treats integrity as a solution to information problems in social coordination.",
          "highlight": {
            "startOffset": 802,
            "endOffset": 1647,
            "quotedText": "If I'm considering breaking a promise to you, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would break the promise under these conditions_. If I made a promise to you, it's usually because I wanted you to believe that I would keep it. So you knowing that I _wouldn't_ keep the promise is usually a cost, often a very large one.\n\n![payshisdebts](https://unstylizedcom.files.wordpress.com/2016/11/payshisdebts.jpg)\n\n_Optimal summary of this post._\n\nIf I'm considering sharing a secret you told me, and I am tallying up the costs and benefits, I consider the additional cost of _you having known that I would share this secret_. In many cases, that would mean that you wouldn't have shared it with me---a cost which is usually larger than whatever benefit I might gain from sharing it now."
          },
          "isValid": true
        },
        {
          "title": "Retrocausality as a Simplifying Heuristic",
          "description": "The author introduces a fascinating thought experiment involving a kind of retrocausal influence that doesn't actually require believing in backward causation. This is similar to Hofstadter's concept of \"superrationality\" and connects to discussions of acausal trade in the rationalist community. The author is using this counterfactual reasoning as a simplifying heuristic for a complex set of game-theoretic considerations. This approach has parallels with Kant's categorical imperative but is grounded in consequentialist reasoning rather than deontological principles. The idea of \"magical retrocausal influence\" serves as a computational shortcut for navigating complex social dynamics.",
          "highlight": {
            "startOffset": 2051,
            "endOffset": 2517,
            "quotedText": "This is a weird kind of effect, since it goes backwards in time and it may contradict what I've actually seen. If I **_know_** that you decided to share the secret with me, what does it mean to imagine my decision causing you not to have shared it?\n\nIt just means that I imagine the counterfactual where you didn't share the secret, and I think about just how bad that would have been---making the decision as if I did not yet know whether you would share it or not."
          },
          "isValid": true
        },
        {
          "title": "Decision-Theoretic Edge Cases",
          "description": "The author acknowledges but downplays the importance of exotic decision-theoretic scenarios like coordination games and nuclear deterrence. This connects to discussions in the rationalist community about the applicability of decision theory to everyday life versus extreme scenarios. The reference to Latvia and Moscow is likely alluding to nuclear deterrence scenarios discussed in game theory literature. The author's pragmatic approach suggests that while these edge cases are theoretically interesting, they're rarely encountered in practice and shouldn't dominate our ethical frameworks. This perspective connects to discussions about the practical relevance of theoretical edge cases in decision theory.",
          "highlight": {
            "startOffset": 4472,
            "endOffset": 5220,
            "quotedText": "Some examples where things get more complicated: if we were trying to think of the same number between 1 and 20, I wouldn't assume that we are going to win because by choosing 17 I cause you to know that I'm the kind of person who picks 17. And if you invade Latvia I'm not going to bomb Moscow, assuming that by being arbitrarily vindictive I guarantee your non-aggression. If you want to figure out what I'd do in these cases, think UDT + the arguments in the rest of this post + a reasonable account of logical uncertainty. Or just ask. Sometimes the answer in fact depends on open philosophical questions. But while I find that integrity comes up surprisingly often, really hard decision-theoretic cases come up about as rarely as you'd expect."
          },
          "isValid": true
        },
        {
          "title": "UDT and Decision Theory Context",
          "description": "The author references UDT (Updateless Decision Theory), which is a key concept in the LessWrong community. UDT is a decision theory that evaluates actions based on what you would have precommitted to before receiving any information, rather than making decisions based only on your current information. This connects to broader discussions on decision theory in the rationalist community, including comparisons with Causal Decision Theory (CDT) and Evidential Decision Theory (EDT). The author's approach to integrity essentially implements a form of UDT in everyday ethical decisions, which aligns with Functional Decision Theory as developed by Eliezer Yudkowsky and Nate Soares.",
          "highlight": {
            "startOffset": 7425,
            "endOffset": 7766,
            "quotedText": "Some of these considerations are only relevant because I make decisions using UDT rather than causal decision theory. I think this is the right way to make decisions (or at least the way that you should decide to make decisions), but your views my vary. At any rate, it's the way that I make decisions, which is all that I'm describing here."
          },
          "isValid": true
        },
        {
          "title": "Non-Linear Effects of Detection Probability",
          "description": "The author presents an insightful analysis of how the magnitude of social punishment doesn't scale linearly with detection probability. This connects to research in behavioral economics on punishment and norm enforcement (e.g., Ernst Fehr's work). In game theory terms, this creates a non-linear expected value calculation that helps explain why integrity-based behavior remains optimal even when detection probability is low. This analysis challenges simplistic models that would predict more unethical behavior as detection probability decreases. The author's graph showing a curved rather than linear relationship represents an important refinement to naive expected value calculations in social contexts.",
          "highlight": {
            "startOffset": 8979,
            "endOffset": 10239,
            "quotedText": "Suppose that Alice and Bob interact, and Alice has either a 50% or 5% chance of detecting Bob's jerk-like behavior. In either case, if she detects bad behavior she is going to make an update about Bob's characteristics. But there are several reasons to expect the 5% chance will have a 10x larger update if it actually happens:\n\n*   If Alice is attempting to impose incentives to elicit pro-social behavior from Bob, then the size of the disincentive needs to be 10x larger. This effect is tempered somewhat if imposing twice as large a cost is more than twice as costly for Alice, but still we expect a significant compensating factor.\n*   For whatever reference class Alice is averaging over (her experiences with Bob, her experiences with people like Bob, other people's experiences with Bob...) Alice has 1/10th as much data about cases with a 5% chance of discovery, and so (once the total number of data points in the class is reasonably large) each data point has nearly 10x as much influence.\n*   In general, I think that people are especially suspicious of people cheating when they probably won't get caught (and consider it more serious evidence about \"real\" character), in a way that helps compensate for whatever gaps exist in the last two points."
          },
          "isValid": true
        },
        {
          "title": "Integrity as Social Value Creation",
          "description": "The author frames integrity as enabling positive-sum interactions and value creation, connecting to economic concepts of gains from trade and social surplus. This perspective aligns with discussions in the EA community about coordination mechanisms that enable greater total value creation. The author's willingness to sacrifice some personal value for social efficiency connects to concepts of Pareto improvements and cooperative equilibria in game theory. This framing shifts integrity from a purely moral concept to an instrumental one that enhances collective welfare, which is particularly relevant to EA discussions about institutional design and cooperation mechanisms.",
          "highlight": {
            "startOffset": 11110,
            "endOffset": 11385,
            "quotedText": "Integrity has one more large advantage: it is often very efficient. Being able to make commitments is useful, as a precondition for most kinds of positive-sum trade. Being able to realize positive-sum trades, without needing to make explicit commitments, is even more useful."
          },
          "isValid": true
        },
        {
          "title": "Integrity as Computational Efficiency",
          "description": "The author makes an important point about computational efficiency that connects to Herbert Simon's concept of bounded rationality and Gigerenzer's work on heuristics. In EA/rationalist terms, this relates to discussions of mental algorithms that produce good outcomes without requiring excessive cognitive resources. The framing of integrity as computationally simple connects to discussions about \"precomputation\" in AI alignment—setting up decision procedures in advance rather than calculating optimal actions in each situation. This perspective treats integrity not just as morally valuable but as instrumentally rational for agents with limited computational resources.",
          "highlight": {
            "startOffset": 12267,
            "endOffset": 12637,
            "quotedText": "\"Behave with integrity\" is a whole lot simpler (computationally and psychologically) than executing a complicated calculation to decide exactly when you can skimp.\n*   Humans have a bunch of emotional responses that seem designed to implement integrity---e.g. vengefulness or a desire to behave honorably---and I find that behaving with integrity also ticks those boxes."
          },
          "isValid": true
        },
        {
          "title": "Integrity vs. Promise-Keeping",
          "description": "The author distinguishes their concept of integrity from strict promise-keeping, addressing a common pattern in consequentialist ethics where absolute rules are justified instrumentally. This connects to discussions in philosophical literature about the nature of promising (e.g., T.M. Scanlon's work) and rule consequentialism. In the rationalist context, this relates to debates about \"rule-following\" versus \"consequence-optimization\" and the concept of \"ethical injunctions\" discussed by Eliezer Yudkowsky. The author is proposing a more nuanced middle ground that captures the benefits of commitment without the rigidity of absolute rules.",
          "highlight": {
            "startOffset": 12825,
            "endOffset": 13272,
            "quotedText": "Many consequentialists claim to adopt firm rules like \"my word is inviolable\" and then justify those rules on consequentialist grounds. But I think on the one hand that approach is too demanding---the people I know who take promises most seriously basically never make them---and on the other it does not go far enough---someone bound by the literal content of their word is only a marginally more useful ally than someone with no scruples at all."
          },
          "isValid": true
        }
      ]
    }
  ]
}