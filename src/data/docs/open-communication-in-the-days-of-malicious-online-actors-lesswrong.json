{
  "id": "open-communication-in-the-days-of-malicious-online-actors-lesswrong",
  "slug": "open-communication-in-the-days-of-malicious-online-actors-lesswrong",
  "title": "Open Communication in the Days of Malicious Online Actors — LessWrong",
  "author": "ozziegooen",
  "publishedDate": "2020-10-07T16:30:01.935Z",
  "url": "https://www.lesswrong.com/posts/YE4md9rNtpjbLGk22/open-communication-in-the-days-of-malicious-online-actors",
  "intendedAgents": [
    "bias-detector",
    "clarity-coach",
    "research-scholar",
    "fake-eliezer",
    "quantitative-forecaster",
    "ea-impact-evaluator"
  ],
  "content": "This is a linkpost for [https://forum.effectivealtruism.org/posts/qWJyPiws7B4XyQGJR/](https://www.lesswrong.com/out?url=https%3A%2F%2Fforum.effectivealtruism.org%2Fposts%2FqWJyPiws7B4XyQGJR%2F)\n\nThis article uses a thought experiment to probe at dangers of public online communication, then describes an ontology around “malicious supporters” and possible remedies.\n\nIt's arguably a more obvious fit for LW than the EA Forum, but I posted it there for reasons explained in the comments. I think people here might also find it interesting though.",
  "reviews": []
}
